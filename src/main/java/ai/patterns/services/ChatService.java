package ai.patterns.services;

import static ai.patterns.utils.Ansi.*;
import static ai.patterns.utils.Models.RERANKING_SCORE_THRESHOLD;
import static ai.patterns.utils.RAGUtils.*;

import ai.patterns.base.AbstractBase;
import ai.patterns.dao.CapitalDataAccessDAO;
import ai.patterns.web.endpoints.ChatEndpoint.ChatOptions;
import dev.langchain4j.data.document.Metadata;
import dev.langchain4j.data.segment.TextSegment;
import dev.langchain4j.memory.chat.MessageWindowChatMemory;
import dev.langchain4j.model.output.Response;
import dev.langchain4j.model.scoring.ScoringModel;
import dev.langchain4j.service.AiServices;
import dev.langchain4j.service.MemoryId;
import dev.langchain4j.service.SystemMessage;
import dev.langchain4j.service.UserMessage;
import dev.langchain4j.service.V;
import java.util.ArrayList;
import java.util.List;
import java.util.Map;
import java.util.concurrent.ConcurrentHashMap;
import java.util.stream.Collectors;
import org.springframework.stereotype.Service;
import reactor.core.publisher.Flux;

@Service
public class ChatService extends AbstractBase {

  private final CapitalDataAccessDAO dataAccess;
  private ChatAssistant assistant = null;
  private final Map<String, MessageWindowChatMemory> chatMemories = new ConcurrentHashMap<>();

  // Create a chat memory instance for this specific chatId
  MessageWindowChatMemory chatMemory = MessageWindowChatMemory.withMaxMessages(10);

  public ChatService(CapitalDataAccessDAO dataAccess) {
    this.dataAccess = dataAccess;
  }

  public String chat(String chatId,
                    String systemMessage,
                    String userMessage,
                    String messageAttachments,
                    ChatOptions options) {
    if(assistant == null) {
      assistant = AiServices.builder(ChatService.ChatAssistant.class)
          .chatLanguageModel(getChatLanguageModel(options.model()))
          .chatMemoryProvider(memoryId -> MessageWindowChatMemory.withMaxMessages(10))
          .build();
    }

    String report = assistant.chat(chatId, systemMessage, userMessage);

    System.out.println(blue("\n>>> FINAL RESPONSE REPORT:\n") + cyan(report));

    return report;
  }

  public Flux<String> stream(String chatId,
                             String systemMessage,
                             String userMessage,
                             String messageAttachments,
                             ChatOptions options) {
    // Get or create chat memory for this specific chatId
    MessageWindowChatMemory chatMemory = chatMemories.computeIfAbsent(chatId,
        id -> MessageWindowChatMemory.withMaxMessages(10));

    // Add system message if provided and memory is empty
    if (systemMessage != null && !systemMessage.isEmpty() && chatMemory.messages().isEmpty()) {
      chatMemory.add(dev.langchain4j.data.message.SystemMessage.from(systemMessage));
    }

    assistant = AiServices.builder(ChatService.ChatAssistant.class)
        .streamingChatLanguageModel(getChatLanguageModelStreaming(options))
        .chatMemoryProvider(memoryId -> chatMemories.getOrDefault(
                  memoryId,
                  MessageWindowChatMemory.withMaxMessages(10)))
        .build();

    // compress the query if required
    if(options.queryCompression()){
      userMessage = compressQuery(chatId, userMessage, chatMemory, getChatLanguageModel(options.model()));

      System.out.println(blue("\n>>> COMPRESSED QUERY:\n") + cyan(userMessage));
    }

    // Hypothetical Document Embedding:
    // search for a hypothetical answer generated by the LLM
    // instead of searching for the original question
    if (options.hyde()) {
      userMessage = hypotheticalAnswer(chatId, userMessage, chatMemory, getChatLanguageModel(options.model()));

      System.out.println(blue("\n>>> HYPOTHETICAL ANSWER:\n") + cyan(userMessage));
    }

    // augment with vector data if RAG is enabled
    // no RAG? ok
    List<CapitalDataAccessDAO.CapitalChunkRow> capitalChunks = new ArrayList<>();
    String additionalVectorData = "";
    String sources = "";

    if (options.enableRAG()) {
      capitalChunks = augmentWithVectorDataList(userMessage,
                                                 options,
                                                 dataAccess);

      if (options.reranking()) {
        System.out.println("\n" + blue(">>> RERANKING\n"));

        ScoringModel scoringModel = getScoringModel();

        List<TextSegment> contents = capitalChunks.stream()
            .map(capitalChunk ->
                new TextSegment(
                    capitalChunk.getContent(),
                    new Metadata(Map.of("id", capitalChunk.getChunkId()))
                )
            )
            .toList();

        Response<List<Double>> scoredCapitalChunks = scoringModel.scoreAll(contents, userMessage);

        for (int i = 0; i < scoredCapitalChunks.content().size(); i++) {
          capitalChunks.get(i).setRerankingScore(scoredCapitalChunks.content().get(i));
          System.out.println("- " + capitalChunks.get(i).getRerankingScore() + " â€” " + cyan(capitalChunks.get(i).getContent()));
        }

        // Keep only chunks with a reranking score above 0.6
        capitalChunks = capitalChunks.stream()
            .filter(capitalChunkRow -> capitalChunkRow.getRerankingScore() > RERANKING_SCORE_THRESHOLD)
            .toList();
      }

      // format RAG data to send to LLM
      additionalVectorData = capitalChunks.stream()
          .map(CapitalDataAccessDAO.CapitalChunkRow::getChunk)
          .collect(Collectors.joining("\n"));

      // format sources in returnable format
      sources = formatSearchResults(capitalChunks);
    }

    //  prepare final UserMessage including original UserMessage, attachments, vector data (if available)
    String finalUserMessage = prepareUserMessage(userMessage,
        messageAttachments,
        additionalVectorData,
        sources,
        options.showDataSources());

    return assistant.stream(chatId, systemMessage, finalUserMessage)
        .doOnNext(System.out::print)
        .doOnComplete(() -> {
          System.out.println(blue("\n\n>>> STREAM COMPLETE")); // Indicate stream completion
        });
  }

  interface ChatAssistant {
    @SystemMessage(fromResource = "templates/chat-service-system.txt")
    String chat(@MemoryId String chatId, @V("systemMessage") String systemMessage, @UserMessage String userMessage);

    @SystemMessage(fromResource = "templates/chat-service-system.txt")
    Flux<String> stream(@MemoryId String chatId, @V("systemMessage") String systemMessage, @UserMessage String userMessage);
  }
}
